#!/usr/bin/env python3
"""
Status Cache - Caches MCP status to avoid repetitive CLI checks

This module provides a caching mechanism for MCP status to improve performance
when listing MCPs. The cache is stored in tool-mcps/mcp.status with file locking
to prevent race conditions.
"""

import json
import time
import fcntl
from pathlib import Path
from typing import Dict, Optional
from datetime import datetime, timedelta


# Cache file location
CACHE_FILE = Path(__file__).parent.parent.parent / "tool-mcps" / "mcp.status"
CACHE_TIMEOUT = 300  # 5 minutes in seconds


class StatusCache:
    """
    Manages status cache for MCPs with file locking.

    The cache stores:
    - timestamp: Last update time
    - statuses: Dict mapping MCP names to their status
    """

    def __init__(self, cache_file: Path = CACHE_FILE, timeout: int = CACHE_TIMEOUT):
        """
        Initialize status cache.

        Args:
            cache_file: Path to cache file
            timeout: Cache timeout in seconds
        """
        self.cache_file = cache_file
        self.timeout = timeout
        self._ensure_cache_dir()

    def _ensure_cache_dir(self):
        """Ensure cache directory exists"""
        self.cache_file.parent.mkdir(parents=True, exist_ok=True)

    def _lock_file(self, file_handle):
        """
        Acquire exclusive lock on file.

        Args:
            file_handle: Open file handle
        """
        fcntl.flock(file_handle.fileno(), fcntl.LOCK_EX)

    def _unlock_file(self, file_handle):
        """
        Release lock on file.

        Args:
            file_handle: Open file handle
        """
        fcntl.flock(file_handle.fileno(), fcntl.LOCK_UN)

    def _read_cache_unsafe(self) -> Dict:
        """
        Read cache without locking (internal use only).

        Returns:
            Cache data dictionary
        """
        if not self.cache_file.exists():
            return {"timestamp": 0, "statuses": {}}

        try:
            with open(self.cache_file, 'r') as f:
                data = json.load(f)
                return data
        except (json.JSONDecodeError, IOError):
            return {"timestamp": 0, "statuses": {}}

    def _write_cache_unsafe(self, data: Dict):
        """
        Write cache without locking (internal use only).

        Args:
            data: Cache data to write
        """
        # Add warning message for manual edits
        data_with_warning = {
            "_warning": "DO NOT EDIT THIS FILE MANUALLY - Generated automatically by ProteinMCP",
            "_info": "This file caches MCP status to improve list command performance",
            **data
        }
        with open(self.cache_file, 'w') as f:
            json.dump(data_with_warning, f, indent=2)

    def read_cache(self) -> Dict:
        """
        Read cache with file locking.

        Returns:
            Cache data dictionary with 'timestamp' and 'statuses' keys
        """
        self._ensure_cache_dir()

        if not self.cache_file.exists():
            return {"timestamp": 0, "statuses": {}}

        try:
            with open(self.cache_file, 'r') as f:
                self._lock_file(f)
                try:
                    data = json.load(f)
                finally:
                    self._unlock_file(f)
                return data
        except (json.JSONDecodeError, IOError):
            return {"timestamp": 0, "statuses": {}}

    def write_cache(self, statuses: Dict[str, str]):
        """
        Write cache with file locking.

        Args:
            statuses: Dictionary mapping MCP names to status strings
        """
        self._ensure_cache_dir()

        data = {
            "_warning": "DO NOT EDIT THIS FILE MANUALLY - Generated automatically by ProteinMCP",
            "_info": "This file caches MCP status to improve list command performance",
            "timestamp": time.time(),
            "statuses": statuses
        }

        # Use 'a+' mode to create file if it doesn't exist, then truncate
        with open(self.cache_file, 'a+') as f:
            self._lock_file(f)
            try:
                f.seek(0)
                f.truncate()
                json.dump(data, f, indent=2)
            finally:
                self._unlock_file(f)

    def is_cache_valid(self) -> bool:
        """
        Check if cache is still valid (not expired).

        Returns:
            True if cache is valid, False otherwise
        """
        cache = self.read_cache()
        timestamp = cache.get("timestamp", 0)

        if timestamp == 0:
            return False

        age = time.time() - timestamp
        return age < self.timeout

    def get_status(self, mcp_name: str) -> Optional[str]:
        """
        Get cached status for an MCP.

        Args:
            mcp_name: Name of the MCP

        Returns:
            Status string if cached and valid, None otherwise
        """
        if not self.is_cache_valid():
            return None

        cache = self.read_cache()
        return cache.get("statuses", {}).get(mcp_name)

    def set_status(self, mcp_name: str, status: str):
        """
        Set status for a single MCP (updates cache).

        Args:
            mcp_name: Name of the MCP
            status: Status string
        """
        cache = self.read_cache()
        statuses = cache.get("statuses", {})
        statuses[mcp_name] = status
        self.write_cache(statuses)

    def update_statuses(self, statuses: Dict[str, str]):
        """
        Update multiple MCP statuses at once.

        Args:
            statuses: Dictionary mapping MCP names to status strings
        """
        cache = self.read_cache()
        cached_statuses = cache.get("statuses", {})
        cached_statuses.update(statuses)
        self.write_cache(cached_statuses)

    def invalidate(self):
        """Invalidate cache by removing the cache file"""
        if self.cache_file.exists():
            self.cache_file.unlink()

    def get_cache_age(self) -> Optional[timedelta]:
        """
        Get age of the cache.

        Returns:
            timedelta representing cache age, or None if no cache exists
        """
        cache = self.read_cache()
        timestamp = cache.get("timestamp", 0)

        if timestamp == 0:
            return None

        return timedelta(seconds=time.time() - timestamp)


# Global cache instance
_global_cache = None


def get_cache() -> StatusCache:
    """
    Get global status cache instance.

    Returns:
        Global StatusCache instance
    """
    global _global_cache
    if _global_cache is None:
        _global_cache = StatusCache()
    return _global_cache
