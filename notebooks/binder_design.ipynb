{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProteinMCP — Binder Design Workflow\n",
    "\n",
    "Design protein binders using BindCraft with GPU-accelerated deep learning for de novo binder generation.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **BindCraft** | De novo binder design using RFdiffusion + ProteinMPNN + AlphaFold2 |\n",
    "| **Async Jobs** | GPU-accelerated design with asynchronous job submission and monitoring |\n",
    "| **Quality Metrics** | pLDDT, pAE, interface scores, composite quality assessment |\n",
    "\n",
    "**Prerequisites:** Docker (with GPU support), Claude Code CLI, ProteinMCP installed locally.\n",
    "\n",
    "**Links:** [GitHub](https://github.com/charlesxu90/ProteinMCP) · [BindCraft](https://github.com/martinpacesa/BindCraft)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── User Configuration ──\n",
    "TARGET_NAME = \"PDL1\"\n",
    "TARGET_CHAINS = \"A\"\n",
    "BINDER_LENGTH = 130\n",
    "NUM_DESIGNS = 3\n",
    "\n",
    "# Optional: set API key here or in .env. If unset, Claude CLI uses your logged-in account.\n",
    "ANTHROPIC_API_KEY = \"\"\n",
    "CLAUDE_MODEL = \"claude-sonnet-4-6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utility and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import select\n",
    "\n",
    "# ---------- Streaming command runner ----------\n",
    "def run_cmd(cmd, cwd=None):\n",
    "    \"\"\"Run a shell command and stream stdout/stderr line-by-line in real time.\"\"\"\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, shell=True, cwd=cwd,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        bufsize=1, text=True,\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(line, end=\"\", flush=True)\n",
    "    proc.wait()\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"\\n\\u26a0\\ufe0f  Command exited with code {proc.returncode}\")\n",
    "    return proc.returncode\n",
    "\n",
    "# ---------- Claude streaming helper ----------\n",
    "def _display_claude_line(line):\n",
    "    \"\"\"Parse a single stream-json line from Claude CLI and print progress.\"\"\"\n",
    "    if not line.strip():\n",
    "        return\n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "        msg_type = data.get('type', '')\n",
    "        subtype = data.get('subtype', '')\n",
    "\n",
    "        if msg_type == 'system':\n",
    "            if subtype == 'init':\n",
    "                session_id = data.get('session_id', '')[:8]\n",
    "                print(f\"  \\U0001f916 Session started: {session_id}...\", flush=True)\n",
    "            elif subtype != 'transcript':\n",
    "                print(f\"  \\u2699\\ufe0f  System: {subtype}\", flush=True)\n",
    "\n",
    "        elif msg_type == 'assistant':\n",
    "            message = data.get('message', {})\n",
    "            for block in message.get('content', []):\n",
    "                block_type = block.get('type', '')\n",
    "                if block_type == 'thinking':\n",
    "                    text = block.get('thinking', '')[:100]\n",
    "                    print(f\"  \\U0001f4ad Thinking: {text}...\", flush=True)\n",
    "                elif block_type == 'text':\n",
    "                    lines = block.get('text', '').strip().split('\\n')\n",
    "                    for tl in lines[:5]:\n",
    "                        if tl.strip():\n",
    "                            print(f\"  {tl}\", flush=True)\n",
    "                    if len(lines) > 5:\n",
    "                        print(f\"  ... ({len(lines) - 5} more lines)\", flush=True)\n",
    "                elif block_type == 'tool_use':\n",
    "                    tool_name = block.get('name', 'unknown')\n",
    "                    tool_input = block.get('input', {})\n",
    "                    if tool_name == 'Bash':\n",
    "                        print(f\"  \\U0001f527 Bash: {tool_input.get('command', '')[:80]}\", flush=True)\n",
    "                    elif tool_name in ('Read', 'Write', 'Edit'):\n",
    "                        print(f\"  \\U0001f4d6 {tool_name}: {tool_input.get('file_path', '')}\", flush=True)\n",
    "                    elif tool_name.startswith('mcp__'):\n",
    "                        print(f\"  \\U0001f50c MCP: {tool_name}\", flush=True)\n",
    "                    else:\n",
    "                        print(f\"  \\U0001f527 {tool_name}\", flush=True)\n",
    "\n",
    "        elif msg_type == 'user':\n",
    "            for block in data.get('message', {}).get('content', []):\n",
    "                if block.get('type') == 'tool_result':\n",
    "                    if block.get('is_error', False):\n",
    "                        err = block.get('content', '')\n",
    "                        err = err[:100] if isinstance(err, str) else str(err)[:100]\n",
    "                        print(f\"  \\u274c Error: {err}\", flush=True)\n",
    "                    else:\n",
    "                        content = block.get('content', '')\n",
    "                        if isinstance(content, str) and content.strip():\n",
    "                            first = content.strip().split('\\n')[0][:80]\n",
    "                            if first:\n",
    "                                print(f\"  \\u2705 Result: {first}\", flush=True)\n",
    "                        else:\n",
    "                            print(f\"  \\u2705 Done\", flush=True)\n",
    "\n",
    "        elif msg_type == 'result':\n",
    "            if subtype == 'success':\n",
    "                print(f\"  \\u2705 Completed successfully\", flush=True)\n",
    "            elif subtype == 'error':\n",
    "                print(f\"  \\u274c Error: {data.get('error', 'Unknown')}\", flush=True)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        if line.strip():\n",
    "            print(f\"  {line}\", flush=True)\n",
    "\n",
    "\n",
    "def run_claude(prompt, allowed_tools=None, cwd=None):\n",
    "    \"\"\"Run Claude CLI with real-time streaming output.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt text to send to Claude (passed via stdin).\n",
    "        allowed_tools: Comma-separated tool names, e.g. \"Bash,Read,Write\".\n",
    "        cwd: Working directory for the claude process.\n",
    "\n",
    "    Returns:\n",
    "        Process return code (0 = success).\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"claude\",\n",
    "        \"--model\", CLAUDE_MODEL,\n",
    "        \"-p\", \"-\",\n",
    "        \"--output-format\", \"stream-json\",\n",
    "        \"--verbose\",\n",
    "        \"--dangerously-skip-permissions\",\n",
    "    ]\n",
    "    if allowed_tools:\n",
    "        cmd += [\"--allowedTools\", allowed_tools]\n",
    "\n",
    "    print(f\"  \\U0001f916 Claude model: {CLAUDE_MODEL}\")\n",
    "    print(f\"  \\U0001f4cb Tools: {allowed_tools or 'all'}\")\n",
    "    print(f\"  \" + \"-\" * 58)\n",
    "\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, cwd=cwd,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True, bufsize=1,\n",
    "    )\n",
    "    proc.stdin.write(prompt)\n",
    "    proc.stdin.close()\n",
    "\n",
    "    while True:\n",
    "        if proc.poll() is not None:\n",
    "            # Drain remaining output\n",
    "            for line in (proc.stdout.read() or '').split('\\n'):\n",
    "                _display_claude_line(line)\n",
    "            for line in (proc.stderr.read() or '').split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"  \\u2699\\ufe0f  {line}\", flush=True)\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            readable, _, _ = select.select([proc.stdout, proc.stderr], [], [], 0.1)\n",
    "        except (ValueError, OSError):\n",
    "            break\n",
    "\n",
    "        for stream in readable:\n",
    "            line = stream.readline()\n",
    "            if line:\n",
    "                if stream == proc.stdout:\n",
    "                    _display_claude_line(line.rstrip('\\n'))\n",
    "                else:\n",
    "                    if line.strip():\n",
    "                        print(f\"  \\u2699\\ufe0f  {line.rstrip()}\", flush=True)\n",
    "\n",
    "    rc = proc.wait()\n",
    "    print(f\"  \" + \"-\" * 58)\n",
    "    if rc != 0:\n",
    "        print(f\"  \\u26a0\\ufe0f  Claude exited with code {rc}\")\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and verify the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API key set — Claude CLI will use your logged-in account.\n",
      "\n",
      "CLAUDE_MODEL   : claude-sonnet-4-6\n",
      "TARGET_NAME    : PDL1\n",
      "TARGET_CHAINS  : A\n",
      "BINDER_LENGTH  : 130\n",
      "NUM_DESIGNS    : 3\n",
      "REPO_DIR       : /home/xux/Desktop/AgentMCP/ProteinMCP\n",
      "DATA_DIR       : /home/xux/Desktop/AgentMCP/ProteinMCP/data/PDL1\n",
      "RESULTS_DIR    : /home/xux/Desktop/AgentMCP/ProteinMCP/results/PDL1_binder\n",
      "TARGET_PDB     : /home/xux/Desktop/AgentMCP/ProteinMCP/data/PDL1/PDL1.pdb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# ---------- Paths ----------\n",
    "# Auto-detect REPO_DIR: walk up from notebook location to find project root\n",
    "_nb_dir = os.path.abspath(\"\")\n",
    "if os.path.basename(_nb_dir) == \"notebooks\":\n",
    "    REPO_DIR = os.path.dirname(_nb_dir)\n",
    "else:\n",
    "    REPO_DIR = _nb_dir\n",
    "\n",
    "# ---------- Load API key from .env if not set ----------\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    _env_file = os.path.join(REPO_DIR, \".env\")\n",
    "    if os.path.exists(_env_file):\n",
    "        with open(_env_file) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"ANTHROPIC_API_KEY=\"):\n",
    "                    ANTHROPIC_API_KEY = line.split(\"=\", 1)[1].strip().strip(\"\\\"'\")\n",
    "                    break\n",
    "        if ANTHROPIC_API_KEY:\n",
    "            print(f\"Loaded ANTHROPIC_API_KEY from {_env_file}\")\n",
    "\n",
    "if ANTHROPIC_API_KEY:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "    print(f\"Using API key (ends with ...{ANTHROPIC_API_KEY[-4:]})\")\n",
    "else:\n",
    "    print(\"No API key set — Claude CLI will use your logged-in account.\")\n",
    "\n",
    "# ---------- Data paths ----------\n",
    "EXAMPLE_DIR = os.path.join(REPO_DIR, \"examples\", \"case2_binder_design\")\n",
    "DATA_DIR    = os.path.join(REPO_DIR, \"data\", TARGET_NAME)\n",
    "RESULTS_DIR = os.path.join(REPO_DIR, \"results\", f\"{TARGET_NAME}_binder\")\n",
    "TARGET_PDB  = os.path.join(DATA_DIR, f\"{TARGET_NAME}.pdb\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"designs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"logs\"), exist_ok=True)\n",
    "\n",
    "# Copy example PDB into DATA_DIR\n",
    "src_pdb = os.path.join(EXAMPLE_DIR, f\"{TARGET_NAME}.pdb\")\n",
    "if os.path.exists(src_pdb) and not os.path.exists(TARGET_PDB):\n",
    "    shutil.copy2(src_pdb, TARGET_PDB)\n",
    "    print(f\"Copied {src_pdb} \\u2192 {TARGET_PDB}\")\n",
    "\n",
    "assert os.path.exists(TARGET_PDB), f\"Target PDB not found: {TARGET_PDB}\"\n",
    "\n",
    "print(f\"\\nCLAUDE_MODEL   : {CLAUDE_MODEL}\")\n",
    "print(f\"TARGET_NAME    : {TARGET_NAME}\")\n",
    "print(f\"TARGET_CHAINS  : {TARGET_CHAINS}\")\n",
    "print(f\"BINDER_LENGTH  : {BINDER_LENGTH}\")\n",
    "print(f\"NUM_DESIGNS    : {NUM_DESIGNS}\")\n",
    "print(f\"REPO_DIR       : {REPO_DIR}\")\n",
    "print(f\"DATA_DIR       : {DATA_DIR}\")\n",
    "print(f\"RESULTS_DIR    : {RESULTS_DIR}\")\n",
    "print(f\"TARGET_PDB     : {TARGET_PDB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Register MCPs\n",
    "\n",
    "> **Tip — Local Docker build:** The `bindcraft_mcp` Docker image is large and may time out\n",
    "> during `pmcp install`. You can build and register it locally instead:\n",
    "> ```bash\n",
    "> cd tool-mcps/bindcraft_mcp && docker build -t bindcraft_mcp:latest . && cd ../..\n",
    "> claude mcp add bindcraft_mcp -- docker run -i --rm --gpus all --ipc=host -v $PWD:$PWD bindcraft_mcp:latest\n",
    "> ```\n",
    "> The install cell below will skip if `bindcraft_mcp` is already registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xux/miniforge3/envs/protein-mcp/bin/pmcp\n",
      "ProteinMCP already installed.\n",
      "/home/xux/.local/bin/claude\n",
      "Claude Code already installed.\n",
      "Docker version 29.2.1, build a5c7197\n",
      "Docker found.\n",
      "\n",
      "ProteinMCP & Claude Code ready.\n",
      "Elapsed: 0.0s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "# Install ProteinMCP if not already present\n",
    "if run_cmd(\"which pmcp\") != 0:\n",
    "    run_cmd(f\"pip install -e {REPO_DIR}\")\n",
    "    run_cmd(f\"pip install -r {REPO_DIR}/requirements.txt\")\n",
    "else:\n",
    "    print(\"ProteinMCP already installed.\")\n",
    "\n",
    "# Install Claude Code if not already present\n",
    "if run_cmd(\"which claude\") != 0:\n",
    "    run_cmd(\"npm install -g @anthropic-ai/claude-code\")\n",
    "else:\n",
    "    print(\"Claude Code already installed.\")\n",
    "\n",
    "# Verify Docker is available (required for bindcraft_mcp)\n",
    "if run_cmd(\"docker --version\") != 0:\n",
    "    print(\"WARNING: Docker not found. bindcraft_mcp requires Docker with GPU support.\")\n",
    "else:\n",
    "    print(\"Docker found.\")\n",
    "\n",
    "print(f\"\\nProteinMCP & Claude Code ready.\")\n",
    "print(f\"Elapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "# Check if bindcraft_mcp is already registered\n",
    "_registered = subprocess.run([\"claude\", \"mcp\", \"list\"], capture_output=True, text=True).stdout\n",
    "if \"bindcraft_mcp\" not in _registered:\n",
    "    print(\"Installing bindcraft_mcp (this may take a while for the Docker image pull)...\")\n",
    "    run_cmd(\"pmcp install bindcraft_mcp\", cwd=REPO_DIR)\n",
    "else:\n",
    "    print(\"bindcraft_mcp already registered. Skipping installation.\")\n",
    "\n",
    "# Verify MCP status\n",
    "print(f\"\\n{'='*50}\")\n",
    "run_cmd(\"claude mcp list\", cwd=REPO_DIR)\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Explore Default Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "Can you show me the available default configurations for BindCraft using the \\\n",
    "bindcraft_mcp server? I want to understand what settings are available for \\\n",
    "binder design. Use the generate_config tool with analysis_type=\"basic\" and \\\n",
    "input_file={TARGET_PDB} to see what settings are generated.\n",
    "\"\"\"\n",
    "\n",
    "run_claude(\n",
    "    prompt,\n",
    "    allowed_tools=\"mcp__bindcraft_mcp__generate_config,Bash,Read\",\n",
    "    cwd=REPO_DIR,\n",
    ")\n",
    "\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Generate Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "CONFIG_DIR = os.path.join(RESULTS_DIR, \"config\")\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "Generate a BindCraft configuration for my target protein at {TARGET_PDB}. \\\n",
    "Target chain(s) {TARGET_CHAINS} and aim for a binder of length {BINDER_LENGTH}. \\\n",
    "Generate {NUM_DESIGNS} designs. \\\n",
    "Save the config to the output directory {CONFIG_DIR}. \\\n",
    "IMPORTANT: The output_file parameter is an output DIRECTORY path, not a file path. \\\n",
    "Please convert relative paths to absolute paths before calling the MCP server.\n",
    "\"\"\"\n",
    "\n",
    "run_claude(\n",
    "    prompt,\n",
    "    allowed_tools=\"mcp__bindcraft_mcp__generate_config,Bash,Read,Write\",\n",
    "    cwd=REPO_DIR,\n",
    ")\n",
    "\n",
    "# Verify config was created — generate_config creates output_dir/target_settings.json\n",
    "config_settings = os.path.join(CONFIG_DIR, \"target_settings.json\")\n",
    "\n",
    "# Find target_settings.json: check expected location, then search recursively\n",
    "config = None\n",
    "if os.path.isfile(config_settings):\n",
    "    with open(config_settings) as f:\n",
    "        config = json.load(f)\n",
    "    print(f\"\\nConfig generated: {config_settings}\")\n",
    "elif os.path.isdir(CONFIG_DIR):\n",
    "    for root, dirs, files in os.walk(CONFIG_DIR):\n",
    "        if \"target_settings.json\" in files:\n",
    "            found = os.path.join(root, \"target_settings.json\")\n",
    "            with open(found) as f:\n",
    "                config = json.load(f)\n",
    "            config_settings = found\n",
    "            print(f\"\\nConfig generated: {found}\")\n",
    "            break\n",
    "elif os.path.isfile(CONFIG_DIR):\n",
    "    with open(CONFIG_DIR) as f:\n",
    "        config = json.load(f)\n",
    "    print(f\"\\nConfig generated: {CONFIG_DIR}\")\n",
    "\n",
    "if config:\n",
    "    print(f\"Config keys: {list(config.keys())}\")\n",
    "    # Track the BindCraft output directory (design_path from settings)\n",
    "    BINDCRAFT_OUTPUT_DIR = config.get(\"design_path\", os.path.join(CONFIG_DIR, \"job_output\"))\n",
    "    print(f\"BindCraft output dir: {BINDCRAFT_OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: Config not found at {CONFIG_DIR}\")\n",
    "    print(\"The design job in the next step will use default settings.\")\n",
    "    BINDCRAFT_OUTPUT_DIR = os.path.join(CONFIG_DIR, \"job_output\")\n",
    "\n",
    "print(f\"Elapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Submit Binder Design Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "_t0 = time.time()\n",
    "\n",
    "# Find the settings file from generate_config output\n",
    "_settings_file = os.path.join(RESULTS_DIR, \"config\", \"target_settings.json\")\n",
    "if os.path.isfile(_settings_file):\n",
    "    config_arg = f\"Use the config file at {_settings_file}.\"\n",
    "else:\n",
    "    config_arg = \"\"\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "Submit an async binder design job for {TARGET_PDB} using BindCraft. \\\n",
    "Generate {NUM_DESIGNS} designs targeting chain(s) {TARGET_CHAINS} with binder \\\n",
    "length {BINDER_LENGTH}. {config_arg}\n",
    "Please convert relative paths to absolute paths before calling the MCP server.\n",
    "After submitting, print the output_dir path so I can monitor progress.\n",
    "\"\"\"\n",
    "\n",
    "# Capture Claude output to extract output_dir\n",
    "proc = subprocess.Popen(\n",
    "    [\"claude\", \"--model\", CLAUDE_MODEL, \"-p\", \"-\",\n",
    "     \"--output-format\", \"stream-json\", \"--verbose\",\n",
    "     \"--dangerously-skip-permissions\",\n",
    "     \"--allowedTools\", \"mcp__bindcraft_mcp__bindcraft_submit,mcp__bindcraft_mcp__validate_config,Bash,Read,Write\"],\n",
    "    cwd=REPO_DIR,\n",
    "    stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "    text=True, bufsize=1,\n",
    ")\n",
    "proc.stdin.write(prompt)\n",
    "proc.stdin.close()\n",
    "\n",
    "full_output = \"\"\n",
    "for line in proc.stdout:\n",
    "    full_output += line\n",
    "    _display_claude_line(line.rstrip('\\n'))\n",
    "proc.wait()\n",
    "\n",
    "# Extract output_dir from the bindcraft_submit response\n",
    "# The response contains \"output_dir\" which is where BindCraft writes results\n",
    "_output_dir_match = re.search(r'\"output_dir\"\\s*:\\s*\"([^\"]+)\"', full_output)\n",
    "if _output_dir_match:\n",
    "    BINDCRAFT_OUTPUT_DIR = _output_dir_match.group(1)\n",
    "    print(f\"\\nBindCraft output directory: {BINDCRAFT_OUTPUT_DIR}\")\n",
    "else:\n",
    "    # Fallback: use design_path from config\n",
    "    if config and \"design_path\" in config:\n",
    "        BINDCRAFT_OUTPUT_DIR = config[\"design_path\"]\n",
    "    else:\n",
    "        BINDCRAFT_OUTPUT_DIR = os.path.join(RESULTS_DIR, \"config\", \"job_output\")\n",
    "    print(f\"\\nUsing fallback output directory: {BINDCRAFT_OUTPUT_DIR}\")\n",
    "\n",
    "print(f\"Elapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Monitor Job Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "LOG_FILE = os.path.join(BINDCRAFT_OUTPUT_DIR, \"bindcraft_run.log\")\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "Check the status of my BindCraft design job. The output directory is {BINDCRAFT_OUTPUT_DIR}. \\\n",
    "Use bindcraft_check_status to get the job status and design counts. \\\n",
    "Also read the last 30 lines of the log file at {LOG_FILE} to show recent progress.\n",
    "\"\"\"\n",
    "\n",
    "run_claude(\n",
    "    prompt,\n",
    "    allowed_tools=\"mcp__bindcraft_mcp__bindcraft_check_status,Bash,Read\",\n",
    "    cwd=REPO_DIR,\n",
    ")\n",
    "\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polling Loop (Optional)\n",
    "\n",
    "Run this cell to poll job status every 5 minutes until the job completes.\n",
    "Interrupt the kernel to stop polling early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "POLL_INTERVAL = 300  # seconds (5 minutes)\n",
    "MAX_POLLS = 60       # stop after 5 hours\n",
    "\n",
    "LOG_FILE = os.path.join(BINDCRAFT_OUTPUT_DIR, \"bindcraft_run.log\")\n",
    "FINAL_CSV = os.path.join(BINDCRAFT_OUTPUT_DIR, \"final_design_stats.csv\")\n",
    "\n",
    "print(f\"Polling {BINDCRAFT_OUTPUT_DIR} every {POLL_INTERVAL//60} min (Ctrl+C to stop)\\n\")\n",
    "\n",
    "for i in range(1, MAX_POLLS + 1):\n",
    "    # Check CSV line counts\n",
    "    import pandas as pd\n",
    "    n_final = 0\n",
    "    if os.path.exists(FINAL_CSV):\n",
    "        try:\n",
    "            df_final = pd.read_csv(FINAL_CSV)\n",
    "            n_final = len(df_final)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Read last log line for current stage\n",
    "    last_line = \"\"\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        with open(LOG_FILE) as f:\n",
    "            lines = f.readlines()\n",
    "            if lines:\n",
    "                last_line = lines[-1].strip()[:120]\n",
    "\n",
    "    ts = time.strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{ts}] Poll #{i}: accepted={n_final}/{NUM_DESIGNS} | {last_line}\")\n",
    "\n",
    "    # Check completion\n",
    "    if n_final >= NUM_DESIGNS:\n",
    "        print(f\"\\nAll {NUM_DESIGNS} designs accepted! Job complete.\")\n",
    "        break\n",
    "\n",
    "    if \"Finished all designs\" in last_line:\n",
    "        print(f\"\\nJob finished (found {n_final} accepted designs).\")\n",
    "        break\n",
    "\n",
    "    time.sleep(POLL_INTERVAL)\n",
    "else:\n",
    "    print(f\"\\nMax polls reached ({MAX_POLLS}). Check status manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — Retrieve Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "_t0 = time.time()\n",
    "\n",
    "# Use bindcraft_check_status to get final results\n",
    "prompt = f\"\"\"\\\n",
    "Check the final results of my completed BindCraft job. \\\n",
    "The output directory is {BINDCRAFT_OUTPUT_DIR}. \\\n",
    "Use bindcraft_check_status to get design counts and metrics. \\\n",
    "Also list the ranked PDB files in {BINDCRAFT_OUTPUT_DIR}/Accepted/Ranked/.\n",
    "\"\"\"\n",
    "\n",
    "run_claude(\n",
    "    prompt,\n",
    "    allowed_tools=\"mcp__bindcraft_mcp__bindcraft_check_status,Bash,Read\",\n",
    "    cwd=REPO_DIR,\n",
    ")\n",
    "\n",
    "# Print metrics from the correct location (BINDCRAFT_OUTPUT_DIR, not RESULTS_DIR/designs/)\n",
    "for name in [\"final_design_stats.csv\", \"mpnn_design_stats.csv\"]:\n",
    "    csv_path = os.path.join(BINDCRAFT_OUTPUT_DIR, name)\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if len(df) > 0:\n",
    "            # Show key metrics columns only\n",
    "            key_cols = ['Rank', 'Design', 'Length', 'Average_pLDDT', 'Average_pTM',\n",
    "                        'Average_i_pTM', 'Average_pAE', 'Average_i_pAE', 'Average_dG',\n",
    "                        'Average_dSASA']\n",
    "            display_cols = [c for c in key_cols if c in df.columns]\n",
    "            print(f\"\\n{name} ({len(df)} designs):\")\n",
    "            print(df[display_cols].to_string(index=False))\n",
    "        else:\n",
    "            print(f\"\\n{name}: empty (no designs passed filters)\")\n",
    "\n",
    "# List ranked PDB files\n",
    "ranked_dir = os.path.join(BINDCRAFT_OUTPUT_DIR, \"Accepted\", \"Ranked\")\n",
    "if os.path.isdir(ranked_dir):\n",
    "    ranked_files = sorted(os.listdir(ranked_dir))\n",
    "    print(f\"\\nRanked PDB files ({len(ranked_files)}):\")\n",
    "    for f in ranked_files:\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 — Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "VIZ_SCRIPT = os.path.join(REPO_DIR, \"workflow-skills\", \"scripts\", \"binder_design_viz.py\")\n",
    "VIZ_OUTPUT_PREFIX = os.path.join(RESULTS_DIR, \"binder_design\")\n",
    "\n",
    "# Install viz deps if needed\n",
    "run_cmd(\"pip install -q matplotlib seaborn scipy Pillow pandas\")\n",
    "\n",
    "# Generate separate figures + merged summary\n",
    "# Point the viz script at BINDCRAFT_OUTPUT_DIR (where final_design_stats.csv lives)\n",
    "# Save figures to RESULTS_DIR with a custom prefix\n",
    "run_cmd(f\"python {VIZ_SCRIPT} {BINDCRAFT_OUTPUT_DIR} --output {VIZ_OUTPUT_PREFIX}\")\n",
    "run_cmd(f\"python {VIZ_SCRIPT} {BINDCRAFT_OUTPUT_DIR} --output {VIZ_OUTPUT_PREFIX}_summary --merged\")\n",
    "\n",
    "# Display figures inline\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Try merged summary first\n",
    "summary_png = f\"{VIZ_OUTPUT_PREFIX}_summary.png\"\n",
    "if os.path.exists(summary_png):\n",
    "    print(\"\\nMerged summary figure:\")\n",
    "    display(Image(filename=summary_png, width=900))\n",
    "\n",
    "# Also display individual figures\n",
    "fig_suffixes = [\n",
    "    \"plddt_comparison\",\n",
    "    \"interface_pae\",\n",
    "    \"quality_scatter\",\n",
    "    \"design_ranking\",\n",
    "    \"metrics_table\",\n",
    "    \"execution_timeline\",\n",
    "]\n",
    "for suffix in fig_suffixes:\n",
    "    fpath = f\"{VIZ_OUTPUT_PREFIX}_{suffix}.png\"\n",
    "    if os.path.exists(fpath):\n",
    "        print(f\"\\n{suffix}:\")\n",
    "        display(Image(filename=fpath, width=500))\n",
    "\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions & Troubleshooting\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "This notebook uses BindCraft to design protein binders through an async job pipeline:\n",
    "\n",
    "1. **Explore Configs** — View available BindCraft configuration templates\n",
    "2. **Generate Config** — Create an optimized config for your target\n",
    "3. **Submit Job** — Launch an async GPU design job (RFdiffusion + ProteinMPNN + AlphaFold2)\n",
    "4. **Monitor Progress** — Check status via MCP + poll logs until completion\n",
    "5. **Retrieve Results** — Load design metrics and list ranked PDB files\n",
    "6. **Visualize** — Generate quality assessment figures\n",
    "\n",
    "### Output Directory Structure\n",
    "\n",
    "BindCraft writes results to `design_path` from `target_settings.json` (typically `config/job_output/`):\n",
    "\n",
    "```\n",
    "RESULTS_DIR/\n",
    "├── config/\n",
    "│   ├── target_settings.json        # BindCraft target settings\n",
    "│   └── job_output/                 # BindCraft output (BINDCRAFT_OUTPUT_DIR)\n",
    "│       ├── Accepted/Ranked/        # Final ranked PDB files\n",
    "│       ├── final_design_stats.csv  # Accepted design metrics\n",
    "│       ├── mpnn_design_stats.csv   # All MPNN design metrics\n",
    "│       ├── trajectory_stats.csv    # Trajectory statistics\n",
    "│       └── bindcraft_run.log       # Execution log\n",
    "└── binder_design_*.png             # Visualization figures\n",
    "```\n",
    "\n",
    "### Available MCP Tools\n",
    "\n",
    "| Tool | Description |\n",
    "|------|-------------|\n",
    "| `mcp__bindcraft_mcp__generate_config` | Analyze PDB and generate config directory |\n",
    "| `mcp__bindcraft_mcp__validate_config` | Validate config before submission |\n",
    "| `mcp__bindcraft_mcp__bindcraft_submit` | Submit async design job |\n",
    "| `mcp__bindcraft_mcp__bindcraft_check_status` | Check job status and design counts |\n",
    "| `mcp__bindcraft_mcp__bindcraft_design_binder` | Run synchronous design (blocking) |\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| `bindcraft_mcp` not found | Run `pmcp install bindcraft_mcp` to pull Docker image |\n",
    "| Job stuck in pending | Check GPU availability and Docker GPU runtime |\n",
    "| Low quality designs (low pLDDT) | Try different binder lengths or specify hotspot residues |\n",
    "| GPU out of memory | Reduce binder length or use smaller model config |\n",
    "| Config generation fails | Verify chain IDs exist in PDB; try default settings |\n",
    "| Empty final_design_stats.csv | Designs didn't pass filters; check `failure_csv.csv` |\n",
    "| Docker image pull timeout | Build locally: `cd tool-mcps/bindcraft_mcp && docker build -t bindcraft_mcp:latest .` |\n",
    "| Visualization fails | Ensure viz script points at `BINDCRAFT_OUTPUT_DIR`, not `RESULTS_DIR` |\n",
    "\n",
    "### Quality Thresholds\n",
    "\n",
    "| Metric | Good | Acceptable | Description |\n",
    "|--------|------|------------|-------------|\n",
    "| pLDDT | ≥80 | ≥70 | Predicted structure confidence (higher is better) |\n",
    "| pAE | ≤5 | ≤10 | Predicted aligned error (lower is better) |\n",
    "| i_pAE | ≤10 | ≤15 | Interface pAE (lower is better) |\n",
    "| i_pTM | ≥0.6 | ≥0.4 | Interface pTM score (higher is better) |\n",
    "\n",
    "### References\n",
    "\n",
    "- [BindCraft](https://github.com/martinpacesa/BindCraft) — De novo binder design\n",
    "- [RFdiffusion](https://github.com/RosettaCommons/RFdiffusion) — Structure diffusion\n",
    "- [ProteinMPNN](https://github.com/dauparas/ProteinMPNN) — Inverse folding\n",
    "- [AlphaFold](https://github.com/google-deepmind/alphafold) — Structure prediction\n",
    "- [ProteinMCP](https://github.com/charlesxu90/ProteinMCP) — This project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
