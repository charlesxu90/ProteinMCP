{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProteinMCP \u2014 Binder Design Workflow\n",
    "\n",
    "Design protein binders using BindCraft with GPU-accelerated deep learning for de novo binder generation.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **BindCraft** | De novo binder design using RFdiffusion + ProteinMPNN + AlphaFold2 |\n",
    "| **Async Jobs** | GPU-accelerated design with asynchronous job submission and monitoring |\n",
    "| **Quality Metrics** | pLDDT, pAE, interface scores, composite quality assessment |\n",
    "\n",
    "**Prerequisites:** Docker (with GPU support), Claude Code CLI, ProteinMCP installed locally.\n",
    "\n",
    "**Links:** [GitHub](https://github.com/charlesxu90/ProteinMCP) \u00b7 [BindCraft](https://github.com/martinpacesa/BindCraft)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 User Configuration \u2500\u2500\n",
    "TARGET_NAME = \"PDL1\"\n",
    "TARGET_CHAINS = \"A\"\n",
    "BINDER_LENGTH = 130\n",
    "NUM_DESIGNS = 3\n",
    "\n",
    "# Optional: set API key here or in .env. If unset, Claude CLI uses your logged-in account.\n",
    "ANTHROPIC_API_KEY = \"\"\n",
    "CLAUDE_MODEL = \"claude-sonnet-4-6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utility and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import select\n",
    "\n",
    "# ---------- Streaming command runner ----------\n",
    "def run_cmd(cmd, cwd=None):\n",
    "    \"\"\"Run a shell command and stream stdout/stderr line-by-line in real time.\"\"\"\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, shell=True, cwd=cwd,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        bufsize=1, text=True,\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(line, end=\"\", flush=True)\n",
    "    proc.wait()\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"\\n\\u26a0\\ufe0f  Command exited with code {proc.returncode}\")\n",
    "    return proc.returncode\n",
    "\n",
    "# ---------- Claude streaming helper ----------\n",
    "def _display_claude_line(line):\n",
    "    \"\"\"Parse a single stream-json line from Claude CLI and print progress.\"\"\"\n",
    "    if not line.strip():\n",
    "        return\n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "        msg_type = data.get('type', '')\n",
    "        subtype = data.get('subtype', '')\n",
    "\n",
    "        if msg_type == 'system':\n",
    "            if subtype == 'init':\n",
    "                session_id = data.get('session_id', '')[:8]\n",
    "                print(f\"  \\U0001f916 Session started: {session_id}...\", flush=True)\n",
    "            elif subtype != 'transcript':\n",
    "                print(f\"  \\u2699\\ufe0f  System: {subtype}\", flush=True)\n",
    "\n",
    "        elif msg_type == 'assistant':\n",
    "            message = data.get('message', {})\n",
    "            for block in message.get('content', []):\n",
    "                block_type = block.get('type', '')\n",
    "                if block_type == 'thinking':\n",
    "                    text = block.get('thinking', '')[:100]\n",
    "                    print(f\"  \\U0001f4ad Thinking: {text}...\", flush=True)\n",
    "                elif block_type == 'text':\n",
    "                    lines = block.get('text', '').strip().split('\\n')\n",
    "                    for tl in lines[:5]:\n",
    "                        if tl.strip():\n",
    "                            print(f\"  {tl}\", flush=True)\n",
    "                    if len(lines) > 5:\n",
    "                        print(f\"  ... ({len(lines) - 5} more lines)\", flush=True)\n",
    "                elif block_type == 'tool_use':\n",
    "                    tool_name = block.get('name', 'unknown')\n",
    "                    tool_input = block.get('input', {})\n",
    "                    if tool_name == 'Bash':\n",
    "                        print(f\"  \\U0001f527 Bash: {tool_input.get('command', '')[:80]}\", flush=True)\n",
    "                    elif tool_name in ('Read', 'Write', 'Edit'):\n",
    "                        print(f\"  \\U0001f4d6 {tool_name}: {tool_input.get('file_path', '')}\", flush=True)\n",
    "                    elif tool_name.startswith('mcp__'):\n",
    "                        print(f\"  \\U0001f50c MCP: {tool_name}\", flush=True)\n",
    "                    else:\n",
    "                        print(f\"  \\U0001f527 {tool_name}\", flush=True)\n",
    "\n",
    "        elif msg_type == 'user':\n",
    "            for block in data.get('message', {}).get('content', []):\n",
    "                if block.get('type') == 'tool_result':\n",
    "                    if block.get('is_error', False):\n",
    "                        err = block.get('content', '')\n",
    "                        err = err[:100] if isinstance(err, str) else str(err)[:100]\n",
    "                        print(f\"  \\u274c Error: {err}\", flush=True)\n",
    "                    else:\n",
    "                        content = block.get('content', '')\n",
    "                        if isinstance(content, str) and content.strip():\n",
    "                            first = content.strip().split('\\n')[0][:80]\n",
    "                            if first:\n",
    "                                print(f\"  \\u2705 Result: {first}\", flush=True)\n",
    "                        else:\n",
    "                            print(f\"  \\u2705 Done\", flush=True)\n",
    "\n",
    "        elif msg_type == 'result':\n",
    "            if subtype == 'success':\n",
    "                print(f\"  \\u2705 Completed successfully\", flush=True)\n",
    "            elif subtype == 'error':\n",
    "                print(f\"  \\u274c Error: {data.get('error', 'Unknown')}\", flush=True)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        if line.strip():\n",
    "            print(f\"  {line}\", flush=True)\n",
    "\n",
    "\n",
    "def run_claude(prompt, allowed_tools=None, cwd=None):\n",
    "    \"\"\"Run Claude CLI with real-time streaming output.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt text to send to Claude (passed via stdin).\n",
    "        allowed_tools: Comma-separated tool names, e.g. \"Bash,Read,Write\".\n",
    "        cwd: Working directory for the claude process.\n",
    "\n",
    "    Returns:\n",
    "        Process return code (0 = success).\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"claude\",\n",
    "        \"--model\", CLAUDE_MODEL,\n",
    "        \"-p\", \"-\",\n",
    "        \"--output-format\", \"stream-json\",\n",
    "        \"--verbose\",\n",
    "        \"--dangerously-skip-permissions\",\n",
    "    ]\n",
    "    if allowed_tools:\n",
    "        cmd += [\"--allowedTools\", allowed_tools]\n",
    "\n",
    "    print(f\"  \\U0001f916 Claude model: {CLAUDE_MODEL}\")\n",
    "    print(f\"  \\U0001f4cb Tools: {allowed_tools or 'all'}\")\n",
    "    print(f\"  \" + \"-\" * 58)\n",
    "\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, cwd=cwd,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True, bufsize=1,\n",
    "    )\n",
    "    proc.stdin.write(prompt)\n",
    "    proc.stdin.close()\n",
    "\n",
    "    while True:\n",
    "        if proc.poll() is not None:\n",
    "            # Drain remaining output\n",
    "            for line in (proc.stdout.read() or '').split('\\n'):\n",
    "                _display_claude_line(line)\n",
    "            for line in (proc.stderr.read() or '').split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"  \\u2699\\ufe0f  {line}\", flush=True)\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            readable, _, _ = select.select([proc.stdout, proc.stderr], [], [], 0.1)\n",
    "        except (ValueError, OSError):\n",
    "            break\n",
    "\n",
    "        for stream in readable:\n",
    "            line = stream.readline()\n",
    "            if line:\n",
    "                if stream == proc.stdout:\n",
    "                    _display_claude_line(line.rstrip('\\n'))\n",
    "                else:\n",
    "                    if line.strip():\n",
    "                        print(f\"  \\u2699\\ufe0f  {line.rstrip()}\", flush=True)\n",
    "\n",
    "    rc = proc.wait()\n",
    "    print(f\"  \" + \"-\" * 58)\n",
    "    if rc != 0:\n",
    "        print(f\"  \\u26a0\\ufe0f  Claude exited with code {rc}\")\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and verify the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# ---------- Paths ----------\n",
    "# Auto-detect REPO_DIR: walk up from notebook location to find project root\n",
    "_nb_dir = os.path.abspath(\"\")\n",
    "if os.path.basename(_nb_dir) == \"notebooks\":\n",
    "    REPO_DIR = os.path.dirname(_nb_dir)\n",
    "else:\n",
    "    REPO_DIR = _nb_dir\n",
    "\n",
    "# ---------- Load API key from .env if not set ----------\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    _env_file = os.path.join(REPO_DIR, \".env\")\n",
    "    if os.path.exists(_env_file):\n",
    "        with open(_env_file) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"ANTHROPIC_API_KEY=\"):\n",
    "                    ANTHROPIC_API_KEY = line.split(\"=\", 1)[1].strip().strip(\"\\\"'\")\n",
    "                    break\n",
    "        if ANTHROPIC_API_KEY:\n",
    "            print(f\"Loaded ANTHROPIC_API_KEY from {_env_file}\")\n",
    "\n",
    "if ANTHROPIC_API_KEY:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "    print(f\"Using API key (ends with ...{ANTHROPIC_API_KEY[-4:]})\")\n",
    "else:\n",
    "    print(\"No API key set \u2014 Claude CLI will use your logged-in account.\")\n",
    "\n",
    "# ---------- Data paths ----------\n",
    "EXAMPLE_DIR = os.path.join(REPO_DIR, \"examples\", \"case2_binder_design\")\n",
    "DATA_DIR    = os.path.join(REPO_DIR, \"data\", TARGET_NAME)\n",
    "RESULTS_DIR = os.path.join(REPO_DIR, \"results\", f\"{TARGET_NAME}_binder\")\n",
    "TARGET_PDB  = os.path.join(DATA_DIR, f\"{TARGET_NAME}.pdb\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"designs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"logs\"), exist_ok=True)\n",
    "\n",
    "# Copy example PDB into DATA_DIR\n",
    "src_pdb = os.path.join(EXAMPLE_DIR, f\"{TARGET_NAME}.pdb\")\n",
    "if os.path.exists(src_pdb) and not os.path.exists(TARGET_PDB):\n",
    "    shutil.copy2(src_pdb, TARGET_PDB)\n",
    "    print(f\"Copied {src_pdb} \\u2192 {TARGET_PDB}\")\n",
    "\n",
    "assert os.path.exists(TARGET_PDB), f\"Target PDB not found: {TARGET_PDB}\"\n",
    "\n",
    "print(f\"\\nCLAUDE_MODEL   : {CLAUDE_MODEL}\")\n",
    "print(f\"TARGET_NAME    : {TARGET_NAME}\")\n",
    "print(f\"TARGET_CHAINS  : {TARGET_CHAINS}\")\n",
    "print(f\"BINDER_LENGTH  : {BINDER_LENGTH}\")\n",
    "print(f\"NUM_DESIGNS    : {NUM_DESIGNS}\")\n",
    "print(f\"REPO_DIR       : {REPO_DIR}\")\n",
    "print(f\"DATA_DIR       : {DATA_DIR}\")\n",
    "print(f\"RESULTS_DIR    : {RESULTS_DIR}\")\n",
    "print(f\"TARGET_PDB     : {TARGET_PDB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Register MCPs\n",
    "\n",
    "> **Tip \u2014 Local Docker build:** The `bindcraft_mcp` Docker image is large and may time out\n",
    "> during `pmcp install`. You can build and register it locally instead:\n",
    "> ```bash\n",
    "> cd tool-mcps/bindcraft_mcp && docker build -t bindcraft_mcp:latest . && cd ../..\n",
    "> claude mcp add bindcraft_mcp -- docker run -i --rm --gpus all --ipc=host -v $PWD:$PWD bindcraft_mcp:latest\n",
    "> ```\n",
    "> The install cell below will skip if `bindcraft_mcp` is already registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "# Install ProteinMCP if not already present\n",
    "if run_cmd(\"which pmcp\") != 0:\n",
    "    run_cmd(f\"pip install -e {REPO_DIR}\")\n",
    "    run_cmd(f\"pip install -r {REPO_DIR}/requirements.txt\")\n",
    "else:\n",
    "    print(\"ProteinMCP already installed.\")\n",
    "\n",
    "# Install Claude Code if not already present\n",
    "if run_cmd(\"which claude\") != 0:\n",
    "    run_cmd(\"npm install -g @anthropic-ai/claude-code\")\n",
    "else:\n",
    "    print(\"Claude Code already installed.\")\n",
    "\n",
    "# Verify Docker is available (required for bindcraft_mcp)\n",
    "if run_cmd(\"docker --version\") != 0:\n",
    "    print(\"WARNING: Docker not found. bindcraft_mcp requires Docker with GPU support.\")\n",
    "else:\n",
    "    print(\"Docker found.\")\n",
    "\n",
    "print(f\"\\nProteinMCP & Claude Code ready.\")\n",
    "print(f\"Elapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "_t0 = time.time()\n",
    "\n",
    "# Check if bindcraft_mcp is already registered\n",
    "_registered = subprocess.run([\"claude\", \"mcp\", \"list\"], capture_output=True, text=True).stdout\n",
    "if \"bindcraft_mcp\" not in _registered:\n",
    "    print(\"Installing bindcraft_mcp (this may take a while for the Docker image pull)...\")\n",
    "    run_cmd(\"pmcp install bindcraft_mcp\", cwd=REPO_DIR)\n",
    "else:\n",
    "    print(\"bindcraft_mcp already registered. Skipping installation.\")\n",
    "\n",
    "# Verify MCP status\n",
    "print(f\"\\n{'='*50}\")\n",
    "run_cmd(\"claude mcp list\", cwd=REPO_DIR)\n",
    "print(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \u2014 Explore Default Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n_t0 = time.time()\n\nprompt = f\"\"\"\\\nCan you show me the available default configurations for BindCraft using the \\\nbindcraft_mcp server? I want to understand what settings are available for \\\nbinder design. Use the generate_config tool with analysis_type=\"basic\" and \\\ninput_file={TARGET_PDB} to see what settings are generated.\n\"\"\"\n\nrun_claude(\n    prompt,\n    allowed_tools=\"mcp__bindcraft_mcp__generate_config,Bash,Read\",\n    cwd=REPO_DIR,\n)\n\nprint(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 \u2014 Generate Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n_t0 = time.time()\n\nCONFIG_DIR = os.path.join(RESULTS_DIR, \"config\")\n\nprompt = f\"\"\"\\\nGenerate a BindCraft configuration for my target protein at {TARGET_PDB}. \\\nTarget chain(s) {TARGET_CHAINS} and aim for a binder of length {BINDER_LENGTH}. \\\nGenerate {NUM_DESIGNS} designs. \\\nSave the config to the output directory {CONFIG_DIR}. \\\nIMPORTANT: The output_file parameter is an output DIRECTORY path, not a file path. \\\nPlease convert relative paths to absolute paths before calling the MCP server.\n\"\"\"\n\nrun_claude(\n    prompt,\n    allowed_tools=\"mcp__bindcraft_mcp__generate_config,Bash,Read,Write\",\n    cwd=REPO_DIR,\n)\n\n# Verify config was created \u2014 generate_config creates output_dir/target_settings.json\nconfig_settings = os.path.join(CONFIG_DIR, \"target_settings.json\")\n\n# Find target_settings.json: check expected location, then search recursively\nconfig = None\nif os.path.isfile(config_settings):\n    with open(config_settings) as f:\n        config = json.load(f)\n    print(f\"\\nConfig generated: {config_settings}\")\nelif os.path.isdir(CONFIG_DIR):\n    for root, dirs, files in os.walk(CONFIG_DIR):\n        if \"target_settings.json\" in files:\n            found = os.path.join(root, \"target_settings.json\")\n            with open(found) as f:\n                config = json.load(f)\n            config_settings = found\n            print(f\"\\nConfig generated: {found}\")\n            break\nelif os.path.isfile(CONFIG_DIR):\n    with open(CONFIG_DIR) as f:\n        config = json.load(f)\n    print(f\"\\nConfig generated: {CONFIG_DIR}\")\n\nif config:\n    print(f\"Config keys: {list(config.keys())}\")\n    # Track the BindCraft output directory (design_path from settings)\n    BINDCRAFT_OUTPUT_DIR = config.get(\"design_path\", os.path.join(CONFIG_DIR, \"job_output\"))\n    print(f\"BindCraft output dir: {BINDCRAFT_OUTPUT_DIR}\")\nelse:\n    print(f\"\\nWARNING: Config not found at {CONFIG_DIR}\")\n    print(\"The design job in the next step will use default settings.\")\n    BINDCRAFT_OUTPUT_DIR = os.path.join(CONFIG_DIR, \"job_output\")\n\nprint(f\"Elapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 \u2014 Submit Binder Design Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time, re\n_t0 = time.time()\n\n# Find the settings file from generate_config output\n_settings_file = os.path.join(RESULTS_DIR, \"config\", \"target_settings.json\")\nif os.path.isfile(_settings_file):\n    config_arg = f\"Use the config file at {_settings_file}.\"\nelse:\n    config_arg = \"\"\n\nprompt = f\"\"\"\\\nSubmit an async binder design job for {TARGET_PDB} using BindCraft. \\\nGenerate {NUM_DESIGNS} designs targeting chain(s) {TARGET_CHAINS} with binder \\\nlength {BINDER_LENGTH}. {config_arg}\nPlease convert relative paths to absolute paths before calling the MCP server.\nAfter submitting, print the output_dir path so I can monitor progress.\n\"\"\"\n\n# Capture Claude output to extract output_dir\nproc = subprocess.Popen(\n    [\"claude\", \"--model\", CLAUDE_MODEL, \"-p\", \"-\",\n     \"--output-format\", \"stream-json\", \"--verbose\",\n     \"--dangerously-skip-permissions\",\n     \"--allowedTools\", \"mcp__bindcraft_mcp__bindcraft_submit,mcp__bindcraft_mcp__validate_config,Bash,Read,Write\"],\n    cwd=REPO_DIR,\n    stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n    text=True, bufsize=1,\n)\nproc.stdin.write(prompt)\nproc.stdin.close()\n\nfull_output = \"\"\nfor line in proc.stdout:\n    full_output += line\n    _display_claude_line(line.rstrip('\\n'))\nproc.wait()\n\n# Extract output_dir from the bindcraft_submit response\n# The response contains \"output_dir\" which is where BindCraft writes results\n_output_dir_match = re.search(r'\"output_dir\"\\s*:\\s*\"([^\"]+)\"', full_output)\nif _output_dir_match:\n    BINDCRAFT_OUTPUT_DIR = _output_dir_match.group(1)\n    print(f\"\\nBindCraft output directory: {BINDCRAFT_OUTPUT_DIR}\")\nelse:\n    # Fallback: use design_path from config\n    if config and \"design_path\" in config:\n        BINDCRAFT_OUTPUT_DIR = config[\"design_path\"]\n    else:\n        BINDCRAFT_OUTPUT_DIR = os.path.join(RESULTS_DIR, \"config\", \"job_output\")\n    print(f\"\\nUsing fallback output directory: {BINDCRAFT_OUTPUT_DIR}\")\n\nprint(f\"Elapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 \u2014 Monitor Job Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n_t0 = time.time()\n\nLOG_FILE = os.path.join(BINDCRAFT_OUTPUT_DIR, \"bindcraft_run.log\")\n\nprompt = f\"\"\"\\\nCheck the status of my BindCraft design job. The output directory is {BINDCRAFT_OUTPUT_DIR}. \\\nUse bindcraft_check_status to get the job status and design counts. \\\nAlso read the last 30 lines of the log file at {LOG_FILE} to show recent progress.\n\"\"\"\n\nrun_claude(\n    prompt,\n    allowed_tools=\"mcp__bindcraft_mcp__bindcraft_check_status,Bash,Read\",\n    cwd=REPO_DIR,\n)\n\nprint(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Polling Loop (Optional)\n\nRun this cell to poll job status every 5 minutes until the job completes.\nInterrupt the kernel to stop polling early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import time\n\nPOLL_INTERVAL = 300  # seconds (5 minutes)\nMAX_POLLS = 60       # stop after 5 hours\n\nLOG_FILE = os.path.join(BINDCRAFT_OUTPUT_DIR, \"bindcraft_run.log\")\nFINAL_CSV = os.path.join(BINDCRAFT_OUTPUT_DIR, \"final_design_stats.csv\")\n\nprint(f\"Polling {BINDCRAFT_OUTPUT_DIR} every {POLL_INTERVAL//60} min (Ctrl+C to stop)\\n\")\n\nfor i in range(1, MAX_POLLS + 1):\n    # Check CSV line counts\n    import pandas as pd\n    n_final = 0\n    if os.path.exists(FINAL_CSV):\n        try:\n            df_final = pd.read_csv(FINAL_CSV)\n            n_final = len(df_final)\n        except Exception:\n            pass\n\n    # Read last log line for current stage\n    last_line = \"\"\n    if os.path.exists(LOG_FILE):\n        with open(LOG_FILE) as f:\n            lines = f.readlines()\n            if lines:\n                last_line = lines[-1].strip()[:120]\n\n    ts = time.strftime(\"%H:%M:%S\")\n    print(f\"[{ts}] Poll #{i}: accepted={n_final}/{NUM_DESIGNS} | {last_line}\")\n\n    # Check completion\n    if n_final >= NUM_DESIGNS:\n        print(f\"\\nAll {NUM_DESIGNS} designs accepted! Job complete.\")\n        break\n\n    if \"Finished all designs\" in last_line:\n        print(f\"\\nJob finished (found {n_final} accepted designs).\")\n        break\n\n    time.sleep(POLL_INTERVAL)\nelse:\n    print(f\"\\nMax polls reached ({MAX_POLLS}). Check status manually.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 \u2014 Retrieve Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nimport pandas as pd\n_t0 = time.time()\n\n# Use bindcraft_check_status to get final results\nprompt = f\"\"\"\\\nCheck the final results of my completed BindCraft job. \\\nThe output directory is {BINDCRAFT_OUTPUT_DIR}. \\\nUse bindcraft_check_status to get design counts and metrics. \\\nAlso list the ranked PDB files in {BINDCRAFT_OUTPUT_DIR}/Accepted/Ranked/.\n\"\"\"\n\nrun_claude(\n    prompt,\n    allowed_tools=\"mcp__bindcraft_mcp__bindcraft_check_status,Bash,Read\",\n    cwd=REPO_DIR,\n)\n\n# Print metrics from the correct location (BINDCRAFT_OUTPUT_DIR, not RESULTS_DIR/designs/)\nfor name in [\"final_design_stats.csv\", \"mpnn_design_stats.csv\"]:\n    csv_path = os.path.join(BINDCRAFT_OUTPUT_DIR, name)\n    if os.path.exists(csv_path):\n        df = pd.read_csv(csv_path)\n        if len(df) > 0:\n            # Show key metrics columns only\n            key_cols = ['Rank', 'Design', 'Length', 'Average_pLDDT', 'Average_pTM',\n                        'Average_i_pTM', 'Average_pAE', 'Average_i_pAE', 'Average_dG',\n                        'Average_dSASA']\n            display_cols = [c for c in key_cols if c in df.columns]\n            print(f\"\\n{name} ({len(df)} designs):\")\n            print(df[display_cols].to_string(index=False))\n        else:\n            print(f\"\\n{name}: empty (no designs passed filters)\")\n\n# List ranked PDB files\nranked_dir = os.path.join(BINDCRAFT_OUTPUT_DIR, \"Accepted\", \"Ranked\")\nif os.path.isdir(ranked_dir):\n    ranked_files = sorted(os.listdir(ranked_dir))\n    print(f\"\\nRanked PDB files ({len(ranked_files)}):\")\n    for f in ranked_files:\n        print(f\"  {f}\")\n\nprint(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 \u2014 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n_t0 = time.time()\n\nVIZ_SCRIPT = os.path.join(REPO_DIR, \"workflow-skills\", \"scripts\", \"binder_design_viz.py\")\nVIZ_OUTPUT_PREFIX = os.path.join(RESULTS_DIR, \"binder_design\")\n\n# Install viz deps if needed\nrun_cmd(\"pip install -q matplotlib seaborn scipy Pillow pandas\")\n\n# Generate separate figures + merged summary\n# Point the viz script at BINDCRAFT_OUTPUT_DIR (where final_design_stats.csv lives)\n# Save figures to RESULTS_DIR with a custom prefix\nrun_cmd(f\"python {VIZ_SCRIPT} {BINDCRAFT_OUTPUT_DIR} --output {VIZ_OUTPUT_PREFIX}\")\nrun_cmd(f\"python {VIZ_SCRIPT} {BINDCRAFT_OUTPUT_DIR} --output {VIZ_OUTPUT_PREFIX}_summary --merged\")\n\n# Display figures inline\nfrom IPython.display import display, Image\n\n# Try merged summary first\nsummary_png = f\"{VIZ_OUTPUT_PREFIX}_summary.png\"\nif os.path.exists(summary_png):\n    print(\"\\nMerged summary figure:\")\n    display(Image(filename=summary_png, width=900))\n\n# Also display individual figures\nfig_suffixes = [\n    \"plddt_comparison\",\n    \"interface_pae\",\n    \"quality_scatter\",\n    \"design_ranking\",\n    \"metrics_table\",\n    \"execution_timeline\",\n]\nfor suffix in fig_suffixes:\n    fpath = f\"{VIZ_OUTPUT_PREFIX}_{suffix}.png\"\n    if os.path.exists(fpath):\n        print(f\"\\n{suffix}:\")\n        display(Image(filename=fpath, width=500))\n\nprint(f\"\\nElapsed: {time.time() - _t0:.1f}s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Instructions & Troubleshooting\n\n### Workflow Overview\n\nThis notebook uses BindCraft to design protein binders through an async job pipeline:\n\n1. **Explore Configs** \u2014 View available BindCraft configuration templates\n2. **Generate Config** \u2014 Create an optimized config for your target\n3. **Submit Job** \u2014 Launch an async GPU design job (RFdiffusion + ProteinMPNN + AlphaFold2)\n4. **Monitor Progress** \u2014 Check status via MCP + poll logs until completion\n5. **Retrieve Results** \u2014 Load design metrics and list ranked PDB files\n6. **Visualize** \u2014 Generate quality assessment figures\n\n### Output Directory Structure\n\nBindCraft writes results to `design_path` from `target_settings.json` (typically `config/job_output/`):\n\n```\nRESULTS_DIR/\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 target_settings.json        # BindCraft target settings\n\u2502   \u2514\u2500\u2500 job_output/                 # BindCraft output (BINDCRAFT_OUTPUT_DIR)\n\u2502       \u251c\u2500\u2500 Accepted/Ranked/        # Final ranked PDB files\n\u2502       \u251c\u2500\u2500 final_design_stats.csv  # Accepted design metrics\n\u2502       \u251c\u2500\u2500 mpnn_design_stats.csv   # All MPNN design metrics\n\u2502       \u251c\u2500\u2500 trajectory_stats.csv    # Trajectory statistics\n\u2502       \u2514\u2500\u2500 bindcraft_run.log       # Execution log\n\u2514\u2500\u2500 binder_design_*.png             # Visualization figures\n```\n\n### Available MCP Tools\n\n| Tool | Description |\n|------|-------------|\n| `mcp__bindcraft_mcp__generate_config` | Analyze PDB and generate config directory |\n| `mcp__bindcraft_mcp__validate_config` | Validate config before submission |\n| `mcp__bindcraft_mcp__bindcraft_submit` | Submit async design job |\n| `mcp__bindcraft_mcp__bindcraft_check_status` | Check job status and design counts |\n| `mcp__bindcraft_mcp__bindcraft_design_binder` | Run synchronous design (blocking) |\n\n### Common Issues\n\n| Problem | Solution |\n|---------|----------|\n| `bindcraft_mcp` not found | Run `pmcp install bindcraft_mcp` to pull Docker image |\n| Job stuck in pending | Check GPU availability and Docker GPU runtime |\n| Low quality designs (low pLDDT) | Try different binder lengths or specify hotspot residues |\n| GPU out of memory | Reduce binder length or use smaller model config |\n| Config generation fails | Verify chain IDs exist in PDB; try default settings |\n| Empty final_design_stats.csv | Designs didn't pass filters; check `failure_csv.csv` |\n| Docker image pull timeout | Build locally: `cd tool-mcps/bindcraft_mcp && docker build -t bindcraft_mcp:latest .` |\n| Visualization fails | Ensure viz script points at `BINDCRAFT_OUTPUT_DIR`, not `RESULTS_DIR` |\n\n### Quality Thresholds\n\n| Metric | Good | Acceptable | Description |\n|--------|------|------------|-------------|\n| pLDDT | \u226580 | \u226570 | Predicted structure confidence (higher is better) |\n| pAE | \u22645 | \u226410 | Predicted aligned error (lower is better) |\n| i_pAE | \u226410 | \u226415 | Interface pAE (lower is better) |\n| i_pTM | \u22650.6 | \u22650.4 | Interface pTM score (higher is better) |\n\n### References\n\n- [BindCraft](https://github.com/martinpacesa/BindCraft) \u2014 De novo binder design\n- [RFdiffusion](https://github.com/RosettaCommons/RFdiffusion) \u2014 Structure diffusion\n- [ProteinMPNN](https://github.com/dauparas/ProteinMPNN) \u2014 Inverse folding\n- [AlphaFold](https://github.com/google-deepmind/alphafold) \u2014 Structure prediction\n- [ProteinMCP](https://github.com/charlesxu90/ProteinMCP) \u2014 This project"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}